"""
å®æ—¶ Rate Limit ç›‘æ§å™¨
åŸºäºæ¯æ¬¡æœç´¢çš„å®é™…æ¶ˆè€—ï¼ŒåŠ¨æ€è®¡ç®—ä¸‹æ¬¡æ‰§è¡Œé—´éš”
"""
import os
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field

from common.Logger import logger


@dataclass
class TokenStatus:
    """å•ä¸ª Token çš„çŠ¶æ€"""
    token: str

    # Search API (30/min)
    search_limit: int = 30
    search_remaining: int = 30
    search_reset: Optional[datetime] = None

    # Core API (5000/hour)
    core_limit: int = 5000
    core_remaining: int = 5000
    core_reset: Optional[datetime] = None

    # ç»Ÿè®¡ä¿¡æ¯
    last_update: datetime = field(default_factory=datetime.now)
    consecutive_errors: int = 0

    def update_search_limit(self, remaining: int, reset_timestamp: int):
        """æ›´æ–° Search API é™é¢"""
        self.search_remaining = remaining
        self.search_reset = datetime.fromtimestamp(reset_timestamp)
        self.last_update = datetime.now()
        self.consecutive_errors = 0  # æˆåŠŸåˆ™é‡ç½®é”™è¯¯è®¡æ•°

    def update_core_limit(self, remaining: int, reset_timestamp: int):
        """æ›´æ–° Core API é™é¢"""
        self.core_remaining = remaining
        self.core_reset = datetime.fromtimestamp(reset_timestamp)
        self.last_update = datetime.now()

    def mark_error(self):
        """æ ‡è®°é”™è¯¯"""
        self.consecutive_errors += 1

    def is_healthy(self) -> bool:
        """æ£€æŸ¥ Token æ˜¯å¦å¥åº·"""
        if self.consecutive_errors >= 3:
            return False
        if self.search_remaining < 5 or self.core_remaining < 100:
            return False
        return True

    def get_health_score(self) -> float:
        """è·å–å¥åº·åˆ†æ•° (0-1)"""
        search_score = self.search_remaining / self.search_limit
        core_score = self.core_remaining / self.core_limit
        error_penalty = max(0, 1 - self.consecutive_errors * 0.2)
        return (search_score * 0.4 + core_score * 0.4 + error_penalty * 0.2)


class RateLimitMonitor:
    """å®æ—¶ Rate Limit ç›‘æ§å™¨"""

    def __init__(self):
        self.tokens: Dict[str, TokenStatus] = {}
        self.last_search_stats: Dict[str, any] = {}

        # å›ºå®šé…ç½®å‚æ•°ï¼ˆåŸºäºç®—æ³•ä¼˜åŒ–åçš„æœ€ä½³å®è·µï¼‰
        self.min_interval_minutes = 15   # æœ€å°é—´éš”15åˆ†é’Ÿ
        self.max_interval_minutes = 120  # æœ€å¤§é—´éš”2å°æ—¶
        self.target_search_reserve = 0.3 # ä¿ç•™30% Searché…é¢ï¼ˆç”¨äºå†·å´è®¡ç®—ï¼‰
        self.target_core_reserve = 0.2   # ä¿ç•™20% Coreé…é¢

    def register_token(self, token: str):
        """æ³¨å†Œ Token"""
        if token not in self.tokens:
            masked = token[:8] + "..." if len(token) > 8 else token
            self.tokens[token] = TokenStatus(token=masked)
            logger.info(f"ğŸ“ Registered token: {masked}")

    def update_from_response(self, token: str, headers: Dict[str, str], api_type: str = "search"):
        """ä»å“åº”å¤´æ›´æ–°é™é¢ä¿¡æ¯"""
        if token not in self.tokens:
            self.register_token(token)

        status = self.tokens[token]

        try:
            remaining = int(headers.get('X-RateLimit-Remaining', 0))
            limit = int(headers.get('X-RateLimit-Limit', 0))
            reset = int(headers.get('X-RateLimit-Reset', 0))

            if api_type == "search":
                status.search_limit = limit or status.search_limit
                status.update_search_limit(remaining, reset)
            else:  # core
                status.core_limit = limit or status.core_limit
                status.update_core_limit(remaining, reset)

        except (ValueError, TypeError) as e:
            logger.warning(f"âš ï¸ Failed to parse rate limit headers: {e}")

    def mark_token_error(self, token: str):
        """æ ‡è®° Token é”™è¯¯"""
        if token in self.tokens:
            self.tokens[token].mark_error()

    def get_healthiest_token(self) -> Optional[str]:
        """è·å–æœ€å¥åº·çš„ Token"""
        if not self.tokens:
            return None

        healthy_tokens = [(t, s.get_health_score()) for t, s in self.tokens.items() if s.is_healthy()]
        if not healthy_tokens:
            return None

        return max(healthy_tokens, key=lambda x: x[1])[0]

    def record_search_execution(self, queries_count: int, files_processed: int,
                               search_requests: int, core_requests: int,
                               duration_seconds: float):
        """è®°å½•ä¸€æ¬¡æœç´¢ä»»åŠ¡çš„æ‰§è¡Œç»Ÿè®¡"""
        self.last_search_stats = {
            'timestamp': datetime.now(),
            'queries_count': queries_count,
            'files_processed': files_processed,
            'search_requests': search_requests,
            'core_requests': core_requests,
            'duration_seconds': duration_seconds,
            'search_rps': search_requests / duration_seconds if duration_seconds > 0 else 0,
            'core_rps': core_requests / duration_seconds if duration_seconds > 0 else 0,
        }

        logger.info(f"ğŸ“Š Search execution stats: {queries_count} queries, "
                   f"{search_requests} search reqs, {core_requests} core reqs, "
                   f"duration: {duration_seconds:.1f}s")

    def calculate_next_interval(self) -> int:
        """
        å®æ—¶è®¡ç®—ä¸‹æ¬¡æ‰§è¡Œé—´éš”ï¼ˆç§’ï¼‰

        æ ¸å¿ƒæ€æƒ³ï¼š
        1. Search API (30æ¬¡/åˆ†é’Ÿ) æ˜¯æ»‘åŠ¨çª—å£ï¼Œç¬æ—¶å‰©ä½™æ¬¡æ•°æ„ä¹‰ä¸å¤§
        2. å…³é”®æ˜¯ï¼šä»»åŠ¡è€—æ—¶ + å†·å´æ—¶é—´ > é™æµçª—å£
        3. åŸºäºå®é™…æ¶ˆè€—é‡è®¡ç®—å®‰å…¨é—´éš”
        """
        if not self.tokens:
            logger.warning("âš ï¸ No tokens registered, using max interval")
            return self.max_interval_minutes * 60

        # å¦‚æœæ²¡æœ‰æ‰§è¡Œå†å²ï¼Œä½¿ç”¨é»˜è®¤æœ€å°é—´éš”
        if not self.last_search_stats:
            logger.info(f"ğŸ§® No execution history, using default interval: {self.min_interval_minutes} min")
            return self.min_interval_minutes * 60

        # ============================================================
        # æ ¸å¿ƒç®—æ³•ï¼šåŸºäºå®é™…æ¶ˆè€—å’Œé™æµæ¢å¤é€Ÿç‡è®¡ç®—å®‰å…¨é—´éš”
        # ============================================================

        last_duration = self.last_search_stats.get('duration_seconds', 0)
        search_reqs = self.last_search_stats.get('search_requests', 0)
        core_reqs = self.last_search_stats.get('core_requests', 0)

        num_tokens = len([s for s in self.tokens.values() if s.is_healthy()])
        if num_tokens == 0:
            logger.warning("âš ï¸ No healthy tokens, using max interval")
            return self.max_interval_minutes * 60

        # 1. Search API é™æµè®¡ç®—ï¼ˆå…³é”®ç“¶é¢ˆï¼‰
        # æ¯ä¸ª token: 30æ¬¡/åˆ†é’Ÿ = 0.5æ¬¡/ç§’
        search_capacity_per_second = 0.5 * num_tokens

        # ä¸Šæ¬¡ä»»åŠ¡çš„å¹³å‡è¯·æ±‚é€Ÿç‡
        if last_duration > 0:
            actual_search_rps = search_reqs / last_duration
        else:
            actual_search_rps = 0

        # å®‰å…¨é—´éš” = è®©æ»‘åŠ¨çª—å£å®Œå…¨æ¸…ç©ºçš„æ—¶é—´
        # å¦‚æœä¸Šæ¬¡ç”¨äº†25æ¬¡ï¼Œéœ€è¦ç­‰60ç§’è®©çª—å£æ¸…ç©º
        # ä½†å› ä¸ºæ˜¯æ»‘åŠ¨çª—å£ï¼Œå®é™…å¯ä»¥æ›´çŸ­

        # è®¡ç®—éœ€è¦å¤šä¹…æ‰èƒ½"è¿˜æ¸…"ä¸Šæ¬¡çš„æ¶ˆè€—
        if actual_search_rps > search_capacity_per_second * 0.8:
            # æ¶ˆè€—é€Ÿç‡æ¥è¿‘å®¹é‡ â†’ éœ€è¦æ›´é•¿å†·å´æ—¶é—´
            search_cooldown = 60 * (1.0 - self.target_search_reserve)  # é»˜è®¤42ç§’
            reason_search = "high_rate"
        else:
            # æ¶ˆè€—é€Ÿç‡æ­£å¸¸ â†’ çŸ­å†·å´
            search_cooldown = 30  # 30ç§’åçª—å£å·²æ¢å¤ä¸€åŠ
            reason_search = "normal_rate"

        # 2. Core API é™æµè®¡ç®—
        # æ¯ä¸ª token: 5000æ¬¡/å°æ—¶ = 1.39æ¬¡/ç§’
        core_capacity_per_second = (5000 / 3600) * num_tokens

        if last_duration > 0:
            actual_core_rps = core_reqs / last_duration
        else:
            actual_core_rps = 0

        # Core API çª—å£æ˜¯1å°æ—¶ï¼Œä½†æˆ‘ä»¬ä¸éœ€è¦ç­‰é‚£ä¹ˆä¹…
        # åªéœ€ç¡®ä¿ä¸‹æ¬¡æ‰§è¡Œæ—¶æœ‰è¶³å¤Ÿé…é¢
        if core_reqs > 0:
            # é¢„ä¼°ä¸‹æ¬¡éœ€è¦çš„é…é¢
            estimated_core_needed = core_reqs * 1.2  # ç•™20%ä½™é‡
            # è®¡ç®—æ¢å¤è¿™äº›é…é¢éœ€è¦å¤šä¹…
            core_cooldown = (estimated_core_needed / core_capacity_per_second) / 60  # åˆ†é’Ÿ
            core_cooldown = min(core_cooldown, 60)  # æœ€å¤šç­‰1å°æ—¶
            reason_core = f"need_{int(estimated_core_needed)}_quota"
        else:
            core_cooldown = 0
            reason_core = "no_core_usage"

        # 3. ç»¼åˆå†³ç­–
        # å–ä¸¤è€…ä¸­è¾ƒå¤§çš„å†·å´æ—¶é—´
        required_cooldown_minutes = max(
            search_cooldown / 60,
            core_cooldown,
            self.min_interval_minutes  # ä¸ä½äºæœ€å°é—´éš”
        )

        # 4. æ ¹æ®å®é™…æ¶ˆè€—é‡è°ƒæ•´
        # å¦‚æœä¸Šæ¬¡æ¶ˆè€—å¾ˆå°‘ï¼Œå¯ä»¥æ›´æ¿€è¿›
        if search_reqs < 50:
            required_cooldown_minutes *= 0.7
            reason_adjust = "low_consumption"
        # å¦‚æœä¸Šæ¬¡æ¶ˆè€—å¾ˆå¤§ï¼Œæ›´ä¿å®ˆ
        elif search_reqs > 200:
            required_cooldown_minutes *= 1.5
            reason_adjust = "high_consumption"
        else:
            reason_adjust = "normal"

        # 5. é™åˆ¶åœ¨é…ç½®èŒƒå›´å†…
        interval_minutes = max(
            self.min_interval_minutes,
            min(self.max_interval_minutes, required_cooldown_minutes)
        )

        interval_seconds = int(interval_minutes * 60)

        logger.info(
            f"ğŸ§® Calculated next interval: {interval_minutes:.1f} min\n"
            f"   Last execution: {last_duration:.1f}s, "
            f"{search_reqs} search reqs ({actual_search_rps:.2f} rps), "
            f"{core_reqs} core reqs ({actual_core_rps:.2f} rps)\n"
            f"   Tokens: {num_tokens}, Search capacity: {search_capacity_per_second:.2f} rps, "
            f"Core capacity: {core_capacity_per_second:.2f} rps\n"
            f"   Cooldown: search={search_cooldown:.1f}s ({reason_search}), "
            f"core={core_cooldown:.1f}min ({reason_core}), "
            f"adjust={reason_adjust}"
        )

        return interval_seconds

    def get_status_summary(self) -> Dict:
        """è·å–çŠ¶æ€æ‘˜è¦"""
        if not self.tokens:
            return {
                'total_tokens': 0,
                'healthy_tokens': 0,
                'tokens': []
            }

        token_details = []
        for token, status in self.tokens.items():
            token_details.append({
                'token': status.token,
                'search_remaining': status.search_remaining,
                'search_limit': status.search_limit,
                'core_remaining': status.core_remaining,
                'core_limit': status.core_limit,
                'health_score': status.get_health_score(),
                'is_healthy': status.is_healthy(),
                'search_reset': status.search_reset.isoformat() if status.search_reset else None,
                'core_reset': status.core_reset.isoformat() if status.core_reset else None,
            })

        return {
            'total_tokens': len(self.tokens),
            'healthy_tokens': sum(1 for s in self.tokens.values() if s.is_healthy()),
            'tokens': token_details,
            'last_search': self.last_search_stats,
            'next_interval_seconds': self.calculate_next_interval(),
        }


# å…¨å±€å®ä¾‹
rate_limit_monitor = RateLimitMonitor()
